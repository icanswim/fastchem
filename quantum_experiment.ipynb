{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [21:40:30] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "from quantum_dataset import QM7, QM7b, QM9, Champs, SuperSet\n",
    "from quantum_learning import Learn, Selector, ChampSelector\n",
    "from quantum_model import FFNet\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss, L1Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'quantum_dataset.QM7'> dataset created...\n",
      "epoch: 0 of 200, train loss: 2036978.2838541667, val loss: 2015669.1770833333\n",
      "epoch: 1 of 200, train loss: 1988982.8177083333, val loss: 1943201.2356770833\n",
      "epoch: 2 of 200, train loss: 1927734.1197916667, val loss: 1858085.732421875\n",
      "epoch: 3 of 200, train loss: 1768152.8860677083, val loss: 1671066.6197916667\n",
      "epoch: 4 of 200, train loss: 1666283.5625, val loss: 1540289.1328125\n",
      "epoch: 5 of 200, train loss: 1446799.396484375, val loss: 1307319.888671875\n",
      "epoch: 6 of 200, train loss: 1200811.294921875, val loss: 1054263.1979166667\n",
      "epoch: 7 of 200, train loss: 1001304.9348958334, val loss: 862263.2493489584\n",
      "epoch: 8 of 200, train loss: 791206.6822916666, val loss: 679329.7102864584\n",
      "epoch: 9 of 200, train loss: 640511.6852213541, val loss: 570077.8541666666\n",
      "epoch: 10 of 200, train loss: 529678.9565429688, val loss: 505068.9244791667\n",
      "epoch: 11 of 200, train loss: 531272.7610677084, val loss: 521740.6168619792\n",
      "epoch: 12 of 200, train loss: 511379.7727864583, val loss: 474502.1373697917\n",
      "epoch: 13 of 200, train loss: 473393.9244791667, val loss: 445014.44921875\n",
      "epoch: 14 of 200, train loss: 382710.3177083333, val loss: 353336.6282552083\n",
      "epoch: 15 of 200, train loss: 328528.5755208333, val loss: 315873.1233723958\n",
      "epoch: 16 of 200, train loss: 307054.7838541667, val loss: 306638.4088541667\n",
      "epoch: 17 of 200, train loss: 304534.7867838542, val loss: 270651.6946614583\n",
      "epoch: 18 of 200, train loss: 304415.59375, val loss: 290953.0930989583\n",
      "epoch: 19 of 200, train loss: 265508.4973958333, val loss: 251949.2109375\n",
      "epoch: 20 of 200, train loss: 261595.5341796875, val loss: 261748.69173177084\n",
      "epoch: 21 of 200, train loss: 260916.37890625, val loss: 251595.68489583334\n",
      "epoch: 22 of 200, train loss: 256469.81477864584, val loss: 245249.01595052084\n",
      "epoch: 23 of 200, train loss: 241329.92838541666, val loss: 231939.8671875\n",
      "epoch: 24 of 200, train loss: 250587.67252604166, val loss: 249634.53515625\n",
      "epoch: 25 of 200, train loss: 239740.478515625, val loss: 227422.82356770834\n",
      "epoch: 26 of 200, train loss: 218377.17057291666, val loss: 204577.36197916666\n",
      "epoch: 27 of 200, train loss: 218036.66666666666, val loss: 207595.802734375\n",
      "epoch: 28 of 200, train loss: 196077.55208333334, val loss: 164793.14485677084\n",
      "epoch: 29 of 200, train loss: 164018.74609375, val loss: 175339.55208333334\n",
      "epoch: 30 of 200, train loss: 161236.97493489584, val loss: 142286.78255208334\n",
      "epoch: 31 of 200, train loss: 142029.47298177084, val loss: 121118.62369791667\n",
      "epoch: 32 of 200, train loss: 133105.42578125, val loss: 146843.90625\n",
      "epoch: 33 of 200, train loss: 156229.38802083334, val loss: 137958.6484375\n",
      "epoch: 34 of 200, train loss: 130724.42415364583, val loss: 109410.28125\n",
      "epoch: 35 of 200, train loss: 112912.00651041667, val loss: 93920.10807291667\n",
      "epoch: 36 of 200, train loss: 116487.25260416667, val loss: 138120.1953125\n",
      "epoch: 37 of 200, train loss: 98078.41927083333, val loss: 94889.609375\n",
      "epoch: 38 of 200, train loss: 107392.37369791667, val loss: 98839.23958333333\n",
      "epoch: 39 of 200, train loss: 85858.91861979167, val loss: 86357.34114583333\n",
      "epoch: 40 of 200, train loss: 85976.34440104167, val loss: 76542.57682291667\n",
      "epoch: 41 of 200, train loss: 97439.7734375, val loss: 84906.63802083333\n",
      "epoch: 42 of 200, train loss: 87606.03841145833, val loss: 84299.07161458333\n",
      "epoch: 43 of 200, train loss: 76428.32552083333, val loss: 79194.5859375\n",
      "epoch: 44 of 200, train loss: 68702.484375, val loss: 67621.197265625\n",
      "epoch: 45 of 200, train loss: 71307.90169270833, val loss: 62273.67578125\n",
      "epoch: 46 of 200, train loss: 63655.609375, val loss: 57247.073567708336\n",
      "epoch: 47 of 200, train loss: 58733.582682291664, val loss: 61804.608723958336\n",
      "epoch: 48 of 200, train loss: 74203.93684895833, val loss: 62317.4296875\n",
      "epoch: 49 of 200, train loss: 82072.12174479167, val loss: 68592.74544270833\n",
      "epoch: 50 of 200, train loss: 72306.38802083333, val loss: 77943.43684895833\n",
      "epoch: 51 of 200, train loss: 57759.339192708336, val loss: 67776.85221354167\n",
      "epoch: 52 of 200, train loss: 58185.561197916664, val loss: 54420.057291666664\n",
      "epoch: 53 of 200, train loss: 54098.532552083336, val loss: 47444.228515625\n",
      "epoch: 54 of 200, train loss: 57945.85546875, val loss: 55114.298828125\n",
      "epoch: 55 of 200, train loss: 63327.9375, val loss: 56248.057942708336\n",
      "epoch: 56 of 200, train loss: 75278.22981770833, val loss: 54912.66796875\n",
      "epoch: 57 of 200, train loss: 45029.704427083336, val loss: 46713.656575520836\n",
      "epoch: 58 of 200, train loss: 54182.6005859375, val loss: 54471.861979166664\n",
      "epoch: 59 of 200, train loss: 49777.9765625, val loss: 40713.575520833336\n",
      "epoch: 60 of 200, train loss: 44139.349609375, val loss: 45444.422526041664\n",
      "epoch: 61 of 200, train loss: 44522.6455078125, val loss: 44161.473307291664\n",
      "epoch: 62 of 200, train loss: 40409.7822265625, val loss: 42369.301432291664\n",
      "epoch: 63 of 200, train loss: 49682.235677083336, val loss: 49968.580729166664\n",
      "epoch: 64 of 200, train loss: 46723.5576171875, val loss: 36044.509114583336\n",
      "epoch: 65 of 200, train loss: 42815.920572916664, val loss: 42052.891927083336\n",
      "epoch: 66 of 200, train loss: 37781.8779296875, val loss: 49826.46875\n",
      "epoch: 67 of 200, train loss: 33618.503743489586, val loss: 46960.417317708336\n",
      "epoch: 68 of 200, train loss: 40251.455078125, val loss: 34721.1630859375\n",
      "epoch: 69 of 200, train loss: 32451.571940104168, val loss: 45039.7890625\n",
      "epoch: 70 of 200, train loss: 42735.698567708336, val loss: 29262.748697916668\n",
      "epoch: 71 of 200, train loss: 38980.7470703125, val loss: 37872.6708984375\n",
      "epoch: 72 of 200, train loss: 33461.59765625, val loss: 35557.785807291664\n",
      "epoch: 73 of 200, train loss: 30850.292317708332, val loss: 33587.734212239586\n",
      "epoch: 74 of 200, train loss: 39427.362467447914, val loss: 39284.736979166664\n",
      "epoch: 75 of 200, train loss: 36550.306640625, val loss: 29117.642740885418\n",
      "epoch: 76 of 200, train loss: 29052.568359375, val loss: 32177.61328125\n",
      "epoch: 77 of 200, train loss: 27995.114827473957, val loss: 32528.91015625\n",
      "epoch: 78 of 200, train loss: 30024.455729166668, val loss: 31521.2431640625\n",
      "epoch: 79 of 200, train loss: 31734.650716145832, val loss: 28386.2138671875\n",
      "epoch: 80 of 200, train loss: 29591.358235677082, val loss: 29132.350748697918\n",
      "epoch: 81 of 200, train loss: 27868.447021484375, val loss: 27569.480794270832\n",
      "epoch: 82 of 200, train loss: 27407.872721354168, val loss: 20328.27783203125\n",
      "epoch: 83 of 200, train loss: 34909.236979166664, val loss: 24030.5927734375\n",
      "epoch: 84 of 200, train loss: 31396.332682291668, val loss: 34330.331380208336\n",
      "epoch: 85 of 200, train loss: 30118.5732421875, val loss: 31683.895670572918\n",
      "epoch: 86 of 200, train loss: 30548.572102864582, val loss: 28475.250813802082\n",
      "epoch: 87 of 200, train loss: 25036.09619140625, val loss: 27121.414876302082\n",
      "epoch: 88 of 200, train loss: 23882.965901692707, val loss: 26738.874267578125\n",
      "epoch: 89 of 200, train loss: 24216.62430826823, val loss: 32829.531901041664\n",
      "epoch: 90 of 200, train loss: 26790.205078125, val loss: 30765.205078125\n",
      "epoch: 91 of 200, train loss: 25414.157877604168, val loss: 26810.11328125\n",
      "epoch: 92 of 200, train loss: 28430.315104166668, val loss: 28012.594401041668\n",
      "epoch: 93 of 200, train loss: 23452.47265625, val loss: 23010.105061848957\n",
      "epoch: 94 of 200, train loss: 30986.567220052082, val loss: 30894.524841308594\n",
      "epoch: 95 of 200, train loss: 26952.657063802082, val loss: 29794.305989583332\n",
      "epoch: 96 of 200, train loss: 25709.616536458332, val loss: 21777.72265625\n",
      "epoch: 97 of 200, train loss: 23117.279459635418, val loss: 27192.669514973957\n",
      "epoch: 98 of 200, train loss: 27126.509440104168, val loss: 24767.576171875\n",
      "epoch: 99 of 200, train loss: 23374.827311197918, val loss: 19134.1240234375\n",
      "epoch: 100 of 200, train loss: 22120.184895833332, val loss: 18681.047485351562\n",
      "epoch: 101 of 200, train loss: 21060.729736328125, val loss: 22356.501953125\n",
      "epoch: 102 of 200, train loss: 25829.735595703125, val loss: 18757.889322916668\n",
      "epoch: 103 of 200, train loss: 20945.455235799152, val loss: 20293.697530110676\n",
      "epoch: 104 of 200, train loss: 16660.138916015625, val loss: 19073.015299479168\n",
      "epoch: 105 of 200, train loss: 18253.535237630207, val loss: 17259.893391927082\n",
      "epoch: 106 of 200, train loss: 18992.909016927082, val loss: 18350.40946451823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 107 of 200, train loss: 21589.192952473957, val loss: 16644.421061197918\n",
      "epoch: 108 of 200, train loss: 21392.740559895832, val loss: 19056.039713541668\n",
      "epoch: 109 of 200, train loss: 20259.9501953125, val loss: 18927.6171875\n",
      "epoch: 110 of 200, train loss: 19590.992268880207, val loss: 14548.252888997396\n",
      "epoch: 111 of 200, train loss: 19367.837565104168, val loss: 19397.18603515625\n",
      "epoch: 112 of 200, train loss: 17869.145060221355, val loss: 14557.150655110678\n",
      "epoch: 113 of 200, train loss: 14632.775919596354, val loss: 18175.081013997395\n",
      "epoch: 114 of 200, train loss: 16219.400553385416, val loss: 15130.11631266276\n",
      "epoch: 115 of 200, train loss: 15475.608235677084, val loss: 15190.382405598959\n",
      "epoch: 116 of 200, train loss: 11349.293111165365, val loss: 13761.853190104166\n",
      "epoch: 117 of 200, train loss: 12728.799565633139, val loss: 15466.652506510416\n",
      "epoch: 118 of 200, train loss: 13292.292856852213, val loss: 13080.306111653646\n",
      "epoch: 119 of 200, train loss: 12488.3056640625, val loss: 11909.812093098959\n",
      "epoch: 120 of 200, train loss: 15381.88623046875, val loss: 14049.152506510416\n",
      "epoch: 121 of 200, train loss: 14215.428873697916, val loss: 11820.0263671875\n",
      "epoch: 122 of 200, train loss: 12426.8330078125, val loss: 11822.106201171875\n",
      "epoch: 123 of 200, train loss: 13577.100952148438, val loss: 13392.598510742188\n",
      "epoch: 124 of 200, train loss: 12347.336100260416, val loss: 12264.833536783854\n",
      "epoch: 125 of 200, train loss: 13768.310139973959, val loss: 9976.511149088541\n",
      "epoch: 126 of 200, train loss: 9354.620416005453, val loss: 9878.097900390625\n",
      "epoch: 127 of 200, train loss: 7623.773244222005, val loss: 8966.190124511719\n",
      "epoch: 128 of 200, train loss: 9677.255655924479, val loss: 8033.274963378906\n",
      "epoch: 129 of 200, train loss: 8453.314778645834, val loss: 8812.346761067709\n",
      "epoch: 130 of 200, train loss: 8820.43940226237, val loss: 8184.0971272786455\n",
      "epoch: 131 of 200, train loss: 8659.739176432291, val loss: 6964.393819173177\n",
      "epoch: 132 of 200, train loss: 7108.0249430338545, val loss: 6056.048807779948\n",
      "epoch: 133 of 200, train loss: 7042.9003499348955, val loss: 7328.264078776042\n",
      "epoch: 134 of 200, train loss: 6343.56787109375, val loss: 7850.844970703125\n",
      "epoch: 135 of 200, train loss: 5813.639821370442, val loss: 5776.358825683594\n",
      "epoch: 136 of 200, train loss: 5904.2444407145185, val loss: 9695.329508463541\n",
      "epoch: 137 of 200, train loss: 6357.8720703125, val loss: 6644.541259765625\n",
      "epoch: 138 of 200, train loss: 7731.121012369792, val loss: 6110.423309326172\n",
      "epoch: 139 of 200, train loss: 6049.2401936848955, val loss: 6660.595540364583\n",
      "epoch: 140 of 200, train loss: 6468.896016438802, val loss: 7614.7738037109375\n",
      "epoch: 141 of 200, train loss: 6628.8991292317705, val loss: 6818.0778401692705\n",
      "epoch: 142 of 200, train loss: 7230.751057942708, val loss: 5783.305745442708\n",
      "epoch: 143 of 200, train loss: 7567.129557291667, val loss: 5379.760284423828\n",
      "epoch: 144 of 200, train loss: 5999.908548990886, val loss: 5684.704508463542\n",
      "epoch: 145 of 200, train loss: 7749.645182291667, val loss: 6587.2334391276045\n",
      "epoch: 146 of 200, train loss: 6526.6221923828125, val loss: 6190.052022298177\n",
      "epoch: 147 of 200, train loss: 6437.511149088542, val loss: 6609.386881510417\n",
      "epoch: 148 of 200, train loss: 7185.942057291667, val loss: 5796.539957682292\n",
      "epoch: 149 of 200, train loss: 5901.560465494792, val loss: 5864.310791015625\n",
      "epoch: 150 of 200, train loss: 5498.952331542969, val loss: 6538.577748616536\n",
      "epoch: 151 of 200, train loss: 6588.4844156901045, val loss: 7077.514241536458\n",
      "epoch: 152 of 200, train loss: 6849.996765136719, val loss: 4310.318501790364\n",
      "epoch: 153 of 200, train loss: 5731.703206380208, val loss: 6439.405924479167\n",
      "epoch: 154 of 200, train loss: 4862.045715332031, val loss: 4298.057963053386\n",
      "epoch: 155 of 200, train loss: 5070.2043050130205, val loss: 5367.241827646892\n",
      "epoch: 156 of 200, train loss: 5414.313456217448, val loss: 5110.8170166015625\n",
      "epoch: 157 of 200, train loss: 5632.681070963542, val loss: 5523.9699300130205\n",
      "epoch: 158 of 200, train loss: 5823.599034627278, val loss: 4889.760823567708\n",
      "epoch: 159 of 200, train loss: 5272.8613688151045, val loss: 4982.9619140625\n",
      "epoch: 160 of 200, train loss: 6184.509338378906, val loss: 5489.407307942708\n",
      "epoch: 161 of 200, train loss: 6070.733833312988, val loss: 5718.4761149088545\n",
      "epoch: 162 of 200, train loss: 5846.940704345703, val loss: 5541.202667236328\n",
      "epoch: 163 of 200, train loss: 5471.412699381511, val loss: 4825.275553385417\n",
      "epoch: 164 of 200, train loss: 4868.126708984375, val loss: 6007.2681070963545\n",
      "epoch: 165 of 200, train loss: 7317.374348958333, val loss: 4714.1901448567705\n",
      "epoch: 166 of 200, train loss: 5329.2777913411455, val loss: 4896.668393452962\n",
      "epoch: 167 of 200, train loss: 5518.4826253255205, val loss: 5611.891357421875\n",
      "epoch: 168 of 200, train loss: 6308.578552246094, val loss: 5265.652913411458\n",
      "epoch: 169 of 200, train loss: 4956.483744303386, val loss: 5020.992004394531\n",
      "epoch: 170 of 200, train loss: 4617.901748657227, val loss: 5203.50639851888\n",
      "epoch: 171 of 200, train loss: 4643.234375, val loss: 5358.911600748698\n",
      "epoch: 172 of 200, train loss: 5087.6413167317705, val loss: 4841.7940673828125\n",
      "epoch: 173 of 200, train loss: 5620.282206217448, val loss: 5141.695170084636\n",
      "epoch: 174 of 200, train loss: 5795.278483072917, val loss: 6416.0030517578125\n",
      "epoch: 175 of 200, train loss: 4883.657643636067, val loss: 4906.157063802083\n",
      "epoch: 176 of 200, train loss: 4869.743815104167, val loss: 4909.0482991536455\n",
      "epoch: 177 of 200, train loss: 5576.956563313802, val loss: 4734.641184488933\n",
      "epoch: 178 of 200, train loss: 5350.600962320964, val loss: 6498.2677815755205\n",
      "epoch: 179 of 200, train loss: 5707.765299479167, val loss: 6709.07568359375\n",
      "epoch: 180 of 200, train loss: 4720.894226074219, val loss: 5531.71088663737\n",
      "epoch: 181 of 200, train loss: 5410.616861979167, val loss: 3923.5504557291665\n",
      "epoch: 182 of 200, train loss: 5896.690592447917, val loss: 5235.0178629557295\n",
      "epoch: 183 of 200, train loss: 4805.240336100261, val loss: 4221.3194580078125\n",
      "epoch: 184 of 200, train loss: 5943.153157552083, val loss: 4400.6745198567705\n",
      "epoch: 185 of 200, train loss: 4731.969401041667, val loss: 3887.5142618815103\n",
      "epoch: 186 of 200, train loss: 5098.511672973633, val loss: 3682.1845703125\n",
      "epoch: 187 of 200, train loss: 4406.474464416504, val loss: 6048.536783854167\n",
      "epoch: 188 of 200, train loss: 4493.687093098958, val loss: 5649.5891520182295\n",
      "epoch: 189 of 200, train loss: 3728.3820597330728, val loss: 4056.3959147135415\n",
      "epoch: 190 of 200, train loss: 4551.945454915364, val loss: 5340.8236083984375\n",
      "epoch: 191 of 200, train loss: 4916.261149088542, val loss: 4599.021993001302\n",
      "epoch: 192 of 200, train loss: 4782.538981119792, val loss: 4838.383728027344\n",
      "epoch: 193 of 200, train loss: 5348.33935546875, val loss: 5086.7666015625\n",
      "epoch: 194 of 200, train loss: 5154.496419270833, val loss: 3857.8162129720054\n",
      "epoch: 195 of 200, train loss: 5894.679423014323, val loss: 4621.446065266927\n",
      "epoch: 196 of 200, train loss: 4823.431396484375, val loss: 4200.1160888671875\n",
      "epoch: 197 of 200, train loss: 4547.775960286458, val loss: 4852.935465494792\n",
      "epoch: 198 of 200, train loss: 6035.9302164713545, val loss: 5609.228108723958\n",
      "epoch: 199 of 200, train loss: 4219.701904296875, val loss: 4064.3200480143228\n",
      "test loss: 4485.783610026042\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning time: 0:01:54.089864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<quantum_learning.Learn at 0x7fdcf02fc690>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params = {'lr': 0.001}\n",
    "model_params = {'D_in': 23*23, \n",
    "                'H': 4096, \n",
    "                'D_out': 1, \n",
    "                'model_name': 'funnel'}\n",
    "ds_params = {}\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "Learn(Dataset=QM7, Model=FFNet, Sampler=Selector, Optimizer=Adam, Criterion=MSELoss, \n",
    "      batch_size=128, epochs=200, opt_params=opt_params, model_params=model_params, \n",
    "      ds_params=ds_params, crit_params=crit_params, save_model=False, load_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = {'lr': 0.001}\n",
    "model_params = {'D_in': 23*23+13, 'H': 4096, 'D_out': 1, 'model_name': 'funnel'}\n",
    "ds_params = {'target': 'E', \n",
    "             'features': ['alpha_p','alpha_s','HOMO_g','HOMO_p','HOMO_z','LUMO_g',\n",
    "                          'LUMO_p','LUMO_z','IP','EA','E1','Emax','Imax']}\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "Learn(Dataset=QM7b, Model=FFNet, Sampler=Selector, \n",
    "      Optimizer=Adam, Criterion=MSELoss, batch_size=128, epochs=20, \n",
    "      opt_params=opt_params, model_params=model_params, ds_params=ds_params, \n",
    "      crit_params=crit_params, save_model=False, load_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = {'lr': 0.001}\n",
    "model_params = {'D_in': 29*29+29+14, 'H': 1024, 'D_out': 1, 'model_name': 'funnel'}\n",
    "ds_params = {'n': 133885, \n",
    "             'features': ['coulomb','mulliken','A','B','C','alpha','homo',\n",
    "                          'lumo','gap','r2','zpve','H','U0','U','G','Cv'], \n",
    "             'target': 'mu',\n",
    "             'dim': 29,\n",
    "             'use_pickle': True}\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "Learn(Dataset=QM9, Model=FFNet, Sampler=Selector, Optimizer=Adam, Criterion=MSELoss,\n",
    "      batch_size=2048, epochs=10, model_params=model_params, ds_params=ds_params, \n",
    "      opt_params=opt_params, crit_params=crit_params, save_model=False, load_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = {'lr': 0.001}\n",
    "model_params = {'D_in': 128+32+64+32+64, 'H': 512, 'D_out': 1, 'model_name': 'funnel'}\n",
    "ds_params = {'n': 4658146, \n",
    "             'features': False,\n",
    "             'use_h5': False,  \n",
    "             'infer': False}\n",
    "crit_params = {'reduction': 'sum'}\n",
    "sample_params = {'split': .1, 'subset': .1}\n",
    "\n",
    "Learn(Dataset=Champs, Model=FFNet, Sampler=ChampSelector, Optimizer=Adam, Criterion=L1Loss,\n",
    "      batch_size=512, epochs=10, model_params=model_params, ds_params=ds_params, \n",
    "      sample_params=sample_params, opt_params=opt_params, crit_params=crit_params, \n",
    "      save_model=False, load_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'D_in': 128+32+64+32+64, 'H': 512, 'D_out': 1, 'model_name': 'funnel'}\n",
    "ds_params = {'n': 4658146, \n",
    "             'features': False,\n",
    "             'use_h5': False,  \n",
    "             'infer': False}\n",
    "\n",
    "Learn(Dataset=Champs, Model=FFNet, Sampler=Selector, batch_size=2048, model_params=model_params, \n",
    "      ds_params=ds_params, load_model='./models/20200603_1206.pth', adapt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_params = {'n': 133885, \n",
    "             'features': ['coulomb','mulliken','A','B','C','alpha','homo',\n",
    "                          'lumo','gap','r2','zpve','H','U0','U','G','Cv'], \n",
    "             'target': 'mu',\n",
    "             'dim': 29,\n",
    "             'use_pickle': True}\n",
    "q = QM9(**ds_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4]\n",
    "b = [2,3,5,6,7,8]\n",
    "\n",
    "c = {i:(True if i in a else False) for i in b}\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [i for i in b if c[i]]\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
